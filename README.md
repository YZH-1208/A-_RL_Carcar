# 1024

149行 要自己改一下圖片路徑  並確定是否有png圖片  png要拿來算A*

新增 and 改變
新增A*算法在340行那邊
pure pursuit有改一下取最近點的方法  不是單純的算距離找最近的點  而是以機器目前的yaw散射出去的方向找最近點
calculate_reward 那邊我把一些不必要的東西註解 我覺得那個會影響機器人的判斷

![Screenshot from 2024-10-24 19-08-40](https://github.com/user-attachments/assets/096f84b7-a688-476e-81f8-3793b45d86e3)
這是經過A* 優化過後的路徑   但因為看的距離超出牆壁的關係  會導致覺得牆另一側的點比現在的好導致pure pursuit在規劃接下來的路徑點時想要往右邊走而撞上牆壁  
所以應該要項辦法讓機器在同一點錯誤一定次數時自動的不要那麼相信pure pursuit 自己探索出一條安全的路 

明天弄讓深度學習知道什麼時候要接管action( action目前是對應到pure pursuit所以執行結果都一樣）(ok
reward的計算目前怪怪的  在step裡面有算  在calculate_reward裡面也有算 不知道哪些有沒有重複到

=======================================================================================

# 1025

讓機器同一點失敗2次以後  下一次在那一點前後3點會由強化學習來控制
但現在強化學習的東西還沒弄好  輸入,輸出,中間算法...
現在輸入是self.state 是一個[4,64,64]的張量 （Batch, Channel, Height, Width） 可能要了解一下輸入的東西
RL Action output: tensor([[2.0000, 0.3454]])   （速度,角度）

另外現在在算waypoint時 不知道為什麼有時後會卡在56點 明明就沒有撞到牆壁而且有繼續跑  可能要看一下
waypoint 算法有問題  現在是當 現在的點距離近的點<0.65 那current_waypoint_index + 1  但是會有車子因為pure pursuit 走了相對平滑的路線而距離太遠吃不到<0.65的判斷 導致後續因為離那個越來越遠而沒有成功判斷到進入下個點位

後面要繼續調整RL算法  輸入看是不是可以改成用png圖片的資訊 加上 速度 角速度 （現在是輸入self.observation_space = (3, 64, 64) 不知道這是什麼  要再研究一下）


=======================================================================================

# 1029 

把張量的東西處理好了  但現在訓練得很鳥  要改一下輸入資料  reward等等

# 1030

改好current_waypoint_index的問題了  但訓練資料  以及reward還沒弄好
